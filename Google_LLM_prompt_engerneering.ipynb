{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/t8101349/RAG-/blob/main/Google_LLM_prompt_engerneering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "10054535-e70f-415d-8818-4577f2d6589e",
      "metadata": {
        "id": "10054535-e70f-415d-8818-4577f2d6589e"
      },
      "source": [
        "# Google AI Studio\n",
        "* https://aistudio.google.com/\n",
        "* https://ai.google.dev/gemini-api/docs?hl=zh-tw\n",
        "* https://ai.google.dev/gemini-api/docs/get-started/tutorial?lang=python&hl=zh-tw"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "3360bfe0-a397-405b-975a-31dac2fedbcd",
      "metadata": {
        "id": "3360bfe0-a397-405b-975a-31dac2fedbcd"
      },
      "outputs": [],
      "source": [
        "! pip install -q -U google-generativeai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "69f801ba-bbb6-4840-95ca-c83d44d4ef0e",
      "metadata": {
        "id": "69f801ba-bbb6-4840-95ca-c83d44d4ef0e"
      },
      "outputs": [],
      "source": [
        "API_KEY = \"AIzaSyCCqrKQb9ymR5i0ZYuLtboCagiRPv7j7fk\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7ac1017d-7c97-4f31-b9fc-597bf2dec57c",
      "metadata": {
        "id": "7ac1017d-7c97-4f31-b9fc-597bf2dec57c"
      },
      "source": [
        "## Load Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "5cacc854-9774-4cae-a7da-b2ff871207a0",
      "metadata": {
        "id": "5cacc854-9774-4cae-a7da-b2ff871207a0"
      },
      "outputs": [],
      "source": [
        "import google.generativeai as genai\n",
        "\n",
        "model = genai.GenerativeModel('gemini-2.0-flash')\n",
        "genai.configure(api_key=API_KEY)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1fd31d43-a13d-4dfb-8625-906294edee0e",
      "metadata": {
        "id": "1fd31d43-a13d-4dfb-8625-906294edee0e"
      },
      "source": [
        "## 產生文字"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "a19f9a87-09f0-4b3b-969d-5cb74a3d251c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277
        },
        "id": "a19f9a87-09f0-4b3b-969d-5cb74a3d251c",
        "outputId": "d5333490-5d79-4ba2-93b0-435ee7b172f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "機器學習 (Machine Learning, ML) 是一種**讓電腦系統從資料中學習，而無需明確程式碼指示它們如何執行特定任務**的技術。換句話說，機器學習允許電腦透過經驗 (資料) 來改進其性能。\n",
            "\n",
            "更精確地說，機器學習的目標是**開發算法，使電腦可以自動識別資料中的模式、做出預測或決策，並隨著時間的推移從資料中學習並改進這些能力。**\n",
            "\n",
            "以下是一些關鍵詞，幫助你更好地理解機器學習的定義：\n",
            "\n",
            "*   **資料 (Data):** 機器學習的燃料。可以是各種形式，例如數字、文本、圖像、聲音等。\n",
            "*   **算法 (Algorithm):** 機器學習模型的基礎。是電腦用來學習和做出預測的一組指令。\n",
            "*   **模型 (Model):** 算法在特定資料集上訓練的結果。代表了從資料中學習到的知識。\n",
            "*   **學習 (Learning):**  機器學習系統基於資料調整其參數，以提高其性能的過程。\n",
            "*   **預測 (Prediction):** 機器學習模型基於學習到的模式，對新資料做出推斷或判斷。\n",
            "*   **自動化 (Automation):**  機器學習旨在使決策或預測過程自動化，而無需人工干預。\n",
            "\n",
            "總而言之，**機器學習是一種通過資料訓練，讓電腦在沒有明確編程的情況下進行學習、預測和決策的技術。**\n",
            "\n"
          ]
        }
      ],
      "source": [
        "prompt = \"機器學習的定義\"\n",
        "response = model.generate_content(prompt)\n",
        "print(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "abcb0c38-81d2-471c-a855-10f404c9a193",
      "metadata": {
        "id": "abcb0c38-81d2-471c-a855-10f404c9a193"
      },
      "source": [
        "### 產生文字串流"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "1d34b9dd-2600-4338-b25f-3f58b0f6ed80",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "1d34b9dd-2600-4338-b25f-3f58b0f6ed80",
        "outputId": "327e71dc-c237-45eb-c088-42da1062b280"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "機器\n",
            "________________________________________________________________________________\n",
            "學習 (\n",
            "________________________________________________________________________________\n",
            "Machine Learning, ML) 是一個廣泛的電腦科學領域，它賦\n",
            "________________________________________________________________________________\n",
            "予電腦 **從數據中學習，而無需進行明確編程** 的能力\n",
            "________________________________________________________________________________\n",
            "。換句話說，機器學習算法能夠識別數據中的模式、做出預測或決策，並隨著數據的累積而不斷改進其性能。\n",
            "\n",
            "更\n",
            "________________________________________________________________________________\n",
            "精確地說，一個被稱為學習的機器，能夠從經驗 E 中學習，關於某任務 T 和某性能度量 P，如果它在\n",
            "________________________________________________________________________________\n",
            " T 上的性能 (由 P 衡量) 隨著 E 的提高而提高。\n",
            "\n",
            "**讓我們分解一下這個定義：**\n",
            "\n",
            "*   **經驗 (Experience, E):** 指的是用於訓練機器學習模型的數據集。這些\n",
            "________________________________________________________________________________\n",
            "數據集可以包含各種各樣的信息，例如圖像、文本、數字數據、聲音等等。\n",
            "\n",
            "*   **任務 (Task, T):**  指的是機器學習模型需要完成的特定目標。常見的任務包括：\n",
            "    *   \n",
            "________________________________________________________________________________\n",
            "**分類 (Classification):** 將輸入數據分配到預定義的類別中 (例如，判斷一封郵件是否為垃圾郵件)。\n",
            "    *   **回歸 (Regression):** 預測一個連續數值 (例如，預測房價)。\n",
            "    *   **聚\n",
            "________________________________________________________________________________\n",
            "類 (Clustering):** 將數據點分組到具有相似特徵的群集中 (例如，根據客戶購買行為對客戶進行分群)。\n",
            "    *   **異常檢測 (Anomaly Detection):** 識別與大多數數據不同的異常數據點 (例如，檢測信用卡欺詐)。\n",
            "\n",
            "________________________________________________________________________________\n",
            "    *   **生成 (Generation):** 根據已有的數據生成新的數據 (例如，生成圖像、文本或音樂)。\n",
            "\n",
            "*   **性能度量 (Performance Metric, P):**  指衡量機器學習模型在執行任務時表現如何的指標。  不同的任務需要不同的性能度量\n",
            "________________________________________________________________________________\n",
            "。  常見的性能度量包括：\n",
            "    *   **準確度 (Accuracy):**  分類正確的樣本百分比。\n",
            "    *   **精確度 (Precision):**  在所有預測為正例的樣本中，實際為正例的比例。\n",
            "    *   **召回\n",
            "________________________________________________________________________________\n",
            "率 (Recall):**  在所有實際為正例的樣本中，被正確預測為正例的比例。\n",
            "    *   **均方誤差 (Mean Squared Error, MSE):**  預測值與實際值之間差異的平方的平均值。\n",
            "    *   **F1 分數\n",
            "________________________________________________________________________________\n",
            " (F1-Score):** 精確度和召回率的調和平均值。\n",
            "\n",
            "**簡而言之，機器學習的本質就是：**\n",
            "\n",
            "*   **給機器提供數據 (E)。**\n",
            "*   **定義機器需要完成的任務 (T)。**\n",
            "*   **使用\n",
            "________________________________________________________________________________\n",
            "性能度量 (P) 來評估機器的表現。**\n",
            "*   **讓機器通過分析數據，找到完成任務的最佳方法，並不斷提高其性能。**\n",
            "\n",
            "**機器學習與傳統編程的區別：**\n",
            "\n",
            "*   **傳統編程:**  程序員编写明确的指令\n",
            "________________________________________________________________________________\n",
            "，告诉计算机如何执行任务。\n",
            "*   **機器學習:**  程序員编写算法，让计算机自己从数据中学习如何执行任务。\n",
            "\n",
            "**機器學習的應用領域非常廣泛，包括：**\n",
            "\n",
            "*   **搜索引擎 (Search Engines):**  例如，Google 使用機器學習來改\n",
            "________________________________________________________________________________\n",
            "進搜索結果的相關性。\n",
            "*   **推薦系統 (Recommendation Systems):**  例如，Amazon 使用機器學習來推薦產品。\n",
            "*   **自然語言處理 (Natural Language Processing, NLP):**  例如，機器翻譯、情感分析、聊天機器人。\n",
            "*   **計算機視覺 (Computer\n",
            "________________________________________________________________________________\n",
            " Vision):**  例如，圖像識別、目標檢測、人臉識別。\n",
            "*   **醫療保健 (Healthcare):**  例如，疾病診斷、藥物研發、個性化醫療。\n",
            "*   **金融 (Finance):**  例如，風險評估、欺詐檢測、\n",
            "________________________________________________________________________________\n",
            "算法交易。\n",
            "\n",
            "總之，機器學習是一個強大且迅速發展的領域，它正在改变我们与计算机互动的方式，并在各个行业中发挥着越来越重要的作用。\n",
            "\n",
            "________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import google.generativeai as genai\n",
        "\n",
        "prompt = \"機器學習的定義\"\n",
        "\n",
        "response = model.generate_content(prompt, stream=True)\n",
        "\n",
        "for chunk in response:\n",
        "  print(chunk.text)\n",
        "  print(\"_\"*80)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e036c6b7-0a6b-4efc-91a9-7965087e482d",
      "metadata": {
        "id": "e036c6b7-0a6b-4efc-91a9-7965087e482d"
      },
      "source": [
        "## 多模態"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "6e2756a1-6a7e-450d-962a-72df35515681",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "id": "6e2756a1-6a7e-450d-962a-72df35515681",
        "outputId": "af0b1c45-8801-4edb-e5cf-bbf35932a15f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "```json\n",
            "[\n",
            "    {\"class\":\"人臉\", \"corr\":[141,168,133,174], \"id\":1, \"age\":55, \"gender\":\"男性\"},\n",
            "    {\"class\":\"人臉\", \"corr\":[291,178,113,156], \"id\":2, \"age\":25, \"gender\":\"女性\"},\n",
            "    {\"class\":\"人臉\", \"corr\":[444,187,112,155], \"id\":3, \"age\":26, \"gender\":\"男性\"},\n",
            "    {\"class\":\"人臉\", \"corr\":[578,197,97,136], \"id\":4, \"age\":50, \"gender\":\"女性\"}\n",
            "]\n",
            "```\n"
          ]
        }
      ],
      "source": [
        "import pathlib\n",
        "import google.generativeai as genai\n",
        "import urllib.request\n",
        "\n",
        "# image1 = {\n",
        "#     'mime_type': 'image/jpeg',\n",
        "#     'data': pathlib.Path('image1.jpg').read_bytes()\n",
        "# }\n",
        "\n",
        "# image1 = {\n",
        "#     'mime_type': 'image/jpeg',\n",
        "#     'data': urllib.request.urlopen(\"https://img.ltn.com.tw/Upload/health/page/800/2022/01/01/phprhI3u1.jpg\").read()\n",
        "# }\n",
        "# prompt = \"照片中有幾根香蕉\"\n",
        "\n",
        "image1 = {\n",
        "    'mime_type': 'image/jpeg',\n",
        "    'data': urllib.request.urlopen(\"https://mentorx.tw/wp-content/gallery/corn_20170511/a_KLB_0298.jpg\").read()\n",
        "}\n",
        "prompt = '''\n",
        "列出照片中人臉的座標，請嚴格按照下面的JSON格式來輸出結果\n",
        "<JSON>\n",
        "[\n",
        "    {\"class\":\"人臉\", \"corr\":[X,Y,W,H], \"id\":1, \"age\":年齡, \"gender\":性別},\n",
        "    {\"class\":\"人臉\", \"corr\":[X,Y,W,H], \"id\":2, \"age\":年齡, \"gender\":性別},\n",
        "    {\"class\":\"人臉\", \"corr\":[X,Y,W,H], \"id\":3, \"age\":年齡, \"gender\":性別},\n",
        "]\n",
        "</JSON>\n",
        "'''\n",
        "\n",
        "\n",
        "response = model.generate_content([prompt, image1])\n",
        "print(response.text)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pathlib\n",
        "import google.generativeai as genai\n",
        "import urllib.request\n",
        "\n",
        "image1 = {\n",
        "    'mime_type': 'image/jpeg',\n",
        "    'data': urllib.request.urlopen(\"https://img.ltn.com.tw/Upload/health/page/800/2022/01/01/phprhI3u1.jpg\").read()\n",
        "}\n",
        "prompt = \"照片中有幾根香蕉\"\n",
        "response = model.generate_content([prompt, image1])\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "eDDDA7XHdhNS",
        "outputId": "c150c736-9a48-4183-cd35-cbbf96ebaecc"
      },
      "id": "eDDDA7XHdhNS",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "照片中有兩串香蕉。一串香蕉是綠色的，另一串香蕉是黃色的。\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "ae5c8b9c-8b34-402a-90af-1e5bd30d281b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "id": "ae5c8b9c-8b34-402a-90af-1e5bd30d281b",
        "outputId": "ed7aca7e-5afb-4f46-b8e8-ae6447392b4c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "```json\n",
            "[\n",
            "    {\"class\":\"香蕉\", \"corr\":[44,53,234,215], \"id\":1, \"color\":\"green\"},\n",
            "    {\"class\":\"香蕉\", \"corr\":[328,299,196,140], \"id\":2, \"color\":\"yellow\"},\n",
            "    {\"class\":\"西瓜\", \"corr\":[83,420,202,174], \"id\":3, \"color\":\"red\"},\n",
            "    {\"class\":\"西瓜\", \"corr\":[480,436,212,176], \"id\":4, \"color\":\"yellow\"},\n",
            "    {\"class\":\"蘋果\", \"corr\":[217,128,52,50], \"id\":5, \"color\":\"red\"},\n",
            "    {\"class\":\"蘋果\", \"corr\":[486,111,50,50], \"id\":6, \"color\":\"red\"},\n",
            "    {\"class\":\"蘋果\", \"corr\":[45,417,63,62], \"id\":7, \"color\":\"yellow\"}\n",
            "]\n",
            "```\n"
          ]
        }
      ],
      "source": [
        "import pathlib\n",
        "import google.generativeai as genai\n",
        "import urllib.request\n",
        "\n",
        "image1 = {\n",
        "    'mime_type': 'image/jpeg',\n",
        "    'data': urllib.request.urlopen(\"https://img.ltn.com.tw/Upload/health/page/800/2022/01/01/phprhI3u1.jpg\").read()\n",
        "}\n",
        "prompt = '''\n",
        "列出照片中物件的座標，請嚴格按照下面的JSON格式來輸出結果。\n",
        "辨識的物件限定為{香蕉、西瓜、蘋果}\n",
        "<JSON>\n",
        "[\n",
        "    {\"class\":\"物件名稱\", \"corr\":[X,Y,W,H], \"id\":1, \"color\":\"物件顏色\"},\n",
        "    {\"class\":\"物件名稱\", \"corr\":[X,Y,W,H], \"id\":2, \"color\":\"物件顏色\"},\n",
        "    {\"class\":\"物件名稱\", \"corr\":[X,Y,W,H], \"id\":3, \"color\":\"物件顏色\"},\n",
        "]\n",
        "</JSON>\n",
        "'''\n",
        "response = model.generate_content([prompt, image1])\n",
        "print(response.text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "08b0a017-a483-4910-bbea-49a446e3ee9b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "id": "08b0a017-a483-4910-bbea-49a446e3ee9b",
        "outputId": "2b500dce-03ce-46f0-b99d-311d581fb526"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*   [人工智慧]\n",
            "*   [Data Science]\n",
            "*   [程式語言]\n",
            "*   [軟體工程]\n",
            "*   [數學]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "book = '''\n",
        "內容介紹:\n",
        "\n",
        "▍attention / self-attention 機制、Transformer、GPT...，大型語言模型 (LLM) 背後的先進技術「硬派」揭密！\n",
        "\n",
        "▍AI 界扛霸子 NVIDIA 的深度學習 (Deep Learning) 指定教材！\n",
        "\n",
        "近年來，在 NVIDIA (輝達) GPU、CUDA 技術的推波助瀾下，深度學習 (Deep Learning) 領域有著爆炸性的成長，例如最為人知的 ChatGPT 正是運用深度學習技術開發出來的當紅應用。\n",
        "\n",
        "□【徹底看懂 ChatGPT 背後核心技術 - Transformer、GPT 的模型架構】\n",
        "\n",
        "自從 ChatGPT 爆紅之後，自然語言處理 (NLP) 一直是深度學習的熱門研究話題，ChatGPT 的背後核心是 GPT 模型，而 GPT 裡面最重要最重要的技術就是最後那個「T」- 也就是大名鼎鼎、使用了 attention (注意力) 機制的 Transformer 模型，這當中所用的建模技術可說是一環扣一環，也容易讓初學者學起來暈的不得了，只要一個關鍵地方沒搞懂，後面就全花了...\n",
        "\n",
        "為此，本書經過精心設計，是帶你看懂 Transformer、GPT...這些先進技術的最佳救星！本書設計了「環環相扣」的 NLP 章節內容，從最末章的 GPT 模型往回推，循序漸進介紹各技術的細節：\n",
        "\n",
        "🔹看懂循環神經網路的缺點就知道為什麼需要 attention 機制以及 seq2seq 架構\n",
        "🔹看懂 attention 機制就能看懂 self-attention 機制\n",
        "🔹看懂 seq2seq 架構就能看懂 Transformer 的 encoder-decoder 架構\n",
        "🔹看懂 self-attention、seq2seq 就能看懂 Transformer\n",
        "🔹看懂 Transformer 就能看懂 GPT\n",
        "\n",
        "你可以深刻感受到次一章的模型架構幾乎都是為了解決前一章模型的特定問題而誕生的，經此一輪學習下來，保證讓你對 attention / self-attention 機制、Transformer、GPT 技術清清楚楚！這絕對是其他書看不到的精彩內容！\n",
        "\n",
        "【★學深度學習先進技術，跟 AI 重要推手 - NVIDIA 學最到位！】\n",
        "\n",
        "NVIDIA 除了在硬體上為 AI 帶來助益外，為了幫助眾多初學者快速上手深度學習，任職於 NVIDIA 的本書作者 Magnus Ekman 凝聚了他多年來在 NVIDIA 所積累的 AI 知識撰寫了本書。本書同時也是 NVIDIA 的教育和培訓部門 -【深度學習機構 (Deep Learning Institute, DLI)】 指定的培訓教材 (https://www.nvidia.com/zh-tw/training/books/)。\n",
        "\n",
        "要學深度學習，跟深度學習的重要推手 NVIDIA 學就對了！眾多紮實的內容保證讓你受益滿滿！\n",
        "\n",
        "本書特色:\n",
        "\n",
        "□【看懂 ChatGPT 背後核心技術 - GPT 的模型架構】\n",
        "attention 機制、self-attention 機制、Transformer、GPT、encoder-decoder、seq2seq、query-key-value 機制、Multi-head、位置編碼 (positional encoding)、預訓練 (pre-train)、微調 (fine-tune)...各種建模技術輕鬆搞懂！\n",
        "\n",
        "□【生成式 AI 語言模型 100% 從零開始打造！】\n",
        "‧用 Colab + tf.Keras 實作【多國語言翻譯模型】、【Auto-Complete 文字自動完成模型】\n",
        "‧從處理原始文字訓練資料 → 切割資料集 → 建構模型 → 模型調校、優化，從頭到尾示範一遍，帶你紮穩大型語言模型 (LLM) 的建模基礎\n",
        "\n",
        "□【深度學習基礎知識學好學滿】\n",
        "‧紮穩根基！不被損失函數 / 梯度下降 / 反向傳播 / 正規化 / 常規化…一拖拉庫技術名詞搞的暈頭轉向！\n",
        "‧深度神經網路基礎 / CNN / RNN / LSTM...基礎概念詳解\n",
        "‧多模態學習 (multimodal learning)、多任務學習 (multitask learning)、自動化模型架構搜尋...熱門主題介紹。\n",
        "\n",
        "□詳細解說, 流暢翻譯\n",
        "本書由【施威銘研究室】監修, 書中針對原書進行大量補充, 並適當添加註解, 幫助讀者更加理解內容！\n",
        "\n",
        "作者簡介\n",
        "Magnus Ekman\n",
        "\n",
        "現為 NVIDIA 架構總監，擁有資訊工程博士學位與多項專利。他於 1990 年代後期首次接觸人工神經網路、親身體會進化計算的威力後，開始鑽研計算機架構，並與妻兒遷往矽谷居住。他曾在昇陽電腦和 Samsung Research America 從事處理器設計和研發。他目前在 NVIDIA 領導一個工程團隊，負責開發自駕車、人工智慧 (AI) 資料中心專用的高效能、低功率 CPU。\n",
        "\n",
        "目錄大綱\n",
        "Ch01 從感知器看神經網路的底層知識\n",
        "1-1  最早的人工神經元 - Rosenblatt 感知器\n",
        "1-2  增加感知器模型的能力\n",
        "1-3  用線性代數實現神經網路模型\n",
        "\n",
        "Ch02 梯度下降法與反向傳播\n",
        "2-1  導數的基礎概念\n",
        "2-2  以梯度下降法 (gradient descent) 對模型訓練問題求解\n",
        "2-3  反向傳播 (back propagation)\n",
        "\n",
        "Ch03 多層神經網路的建立與調校\n",
        "3-1  動手實作：建立辨識手寫數字的多層神經網路\n",
        "3-2  改善神經網路的訓練成效\n",
        "3-3  實驗：調整神經網路與學習參數\n",
        "\n",
        "Ch04 用卷積神經網路 (CNN) 進行圖片辨識\n",
        "4-1  卷積神經網路 (CNN)\n",
        "4-2  實作：以卷積神經網路做圖片分類\n",
        "4-3  更深層的 CNN 與預訓練模型\n",
        "\n",
        "Ch05 用循環神經網路 (RNN、LSTM...) 處理序列資料\n",
        "5-1  RNN 的基本概念\n",
        "5-2  RNN 範例：預測書店銷售額\n",
        "5-3  LSTM (長短期記憶神經網路)\n",
        "5-4  LSTM 範例：文字的 Auto-Complete 機制\n",
        "\n",
        "Ch06 自然語言處理的重要前置工作：建立詞向量空間\n",
        "6-1  詞向量空間的基本知識\n",
        "6-2  做法(一)：在神經網路建模過程中「順便」生成詞向量空間\n",
        "6-3  做法(二)：以 word2vec、GloVe 專用演算法生成詞向量空間\n",
        "\n",
        "Ch07 用機器翻譯模型熟悉 seq2seq 架構\n",
        "7-1  機器翻譯模型的基本知識\n",
        "7-2  機器翻譯的範例實作\n",
        "7-2-1  tf.Keras 函數式 API 簡介\n",
        "7-2-2  建構模型前的工作\n",
        "7-2-3  建構模型\n",
        "7-2-4  訓練及測試模型\n",
        "7-2-5  實驗結果\n",
        "\n",
        "Ch08 認識 attention 與 self-attention 機制\n",
        "8-1  熟悉 attention 機制\n",
        "8-2  認識 self-attention 機制\n",
        "8-2-1 self-attention 的基本概念\n",
        "8-2-2 self-attention 機制的算法\n",
        "8-2-3 multi-head (多頭) 的 self-attention 機制\n",
        "\n",
        "Ch09 Transformer、GPT 及其他衍生模型架構\n",
        "9-1  Transformer 架構\n",
        "9-1-1 編碼器端的架構\n",
        "9-1-2 解碼器端的架構\n",
        "9-1-3 Transformer 內的其他設計\n",
        "9-1-4 小編補充：觀摩 keras 官網上的 Transformer 範例\n",
        "9-2 Transformer 架構的衍生模型：GPT、BERT\n",
        "9-2-1  認識 GPT 模型\n",
        "9-2-2  認識 BERT 模型\n",
        "9-2-3 其他從 Transformer 衍生出的模型\n",
        "\n",
        "附錄 A 延伸學習 (一)：多模態、多任務...等模型建構相關主題\n",
        "附錄 B 延伸學習 (二)：自動化模型架構搜尋\n",
        "附錄 C 延伸學習 (三)：後續學習方向建議\n",
        "附錄 D 使用 Google 的 Colab 雲端開發環境\n",
        "'''\n",
        "\n",
        "prompt = '''\n",
        "請依照下面的書籍描述來將書籍進行分類，分類的類別只能從下面複選：\n",
        "[程式語言, Data Science, 人工智慧, 分散式架構, 系統開發, 行動軟體開發, 資料庫, 資訊科學, 軟體架構, 軟體測試, 軟體工程, 資訊安全, 網站開發, 前端開發, 架站軟體, 網頁設計, Adobe 軟體應用, Office 系列, 遊戲開發設計, UI/UX, 雲端運算, 區塊鏈與金融科技, 物聯網 IoT, 商業管理類, 電子電路電機類, 嵌入式系統, 視覺影音設計, 考試認證, 數學, 微軟技術, MAC OS 蘋果電腦, 其他, 兒童專區, 製圖軟體應用, 語言學習, 國家考試, 職涯發展, Java, 理工類, 網路通訊, 量子電腦]\n",
        "\n",
        "<書籍描述>\n",
        "{書籍描述}\n",
        "</書籍描述>\n",
        "'''\n",
        "\n",
        "\n",
        "response = model.generate_content(prompt.format(書籍描述=book))\n",
        "print(response.text)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install gradio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7fabUERmeuL6",
        "outputId": "edb88d08-f2f1-47cd-dc92-960bbd28d42f"
      },
      "id": "7fabUERmeuL6",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gradio\n",
            "  Downloading gradio-5.23.3-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting aiofiles<24.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.9.0)\n",
            "Collecting fastapi<1.0,>=0.115.2 (from gradio)\n",
            "  Downloading fastapi-0.115.12-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.5.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting gradio-client==1.8.0 (from gradio)\n",
            "  Downloading gradio_client-1.8.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting groovy~=0.1 (from gradio)\n",
            "  Downloading groovy-0.1.2-py3-none-any.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.30.1)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.0.2)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.16)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.1.0)\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.11.1)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting python-multipart>=0.0.18 (from gradio)\n",
            "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n",
            "Collecting ruff>=0.9.3 (from gradio)\n",
            "  Downloading ruff-0.11.4-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Collecting safehttpx<0.2.0,>=0.1.6 (from gradio)\n",
            "  Downloading safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting starlette<1.0,>=0.40.0 (from gradio)\n",
            "  Downloading starlette-0.46.1-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting tomlkit<0.14.0,>=0.12.0 (from gradio)\n",
            "  Downloading tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.15.2)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.13.0)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.34.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.8.0->gradio) (2025.3.2)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.8.0->gradio) (15.0.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (3.18.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (4.67.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (2.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Downloading gradio-5.23.3-py3-none-any.whl (46.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.5/46.5 MB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.8.0-py3-none-any.whl (322 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.2/322.2 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading fastapi-0.115.12-py3-none-any.whl (95 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading groovy-0.1.2-py3-none-any.whl (14 kB)\n",
            "Downloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
            "Downloading ruff-0.11.4-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m81.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\n",
            "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading starlette-0.46.1-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomlkit-0.13.2-py3-none-any.whl (37 kB)\n",
            "Downloading uvicorn-0.34.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ffmpy-0.5.0-py3-none-any.whl (6.0 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub, uvicorn, tomlkit, semantic-version, ruff, python-multipart, groovy, ffmpy, aiofiles, starlette, safehttpx, gradio-client, fastapi, gradio\n",
            "Successfully installed aiofiles-23.2.1 fastapi-0.115.12 ffmpy-0.5.0 gradio-5.23.3 gradio-client-1.8.0 groovy-0.1.2 pydub-0.25.1 python-multipart-0.0.20 ruff-0.11.4 safehttpx-0.1.6 semantic-version-2.10.0 starlette-0.46.1 tomlkit-0.13.2 uvicorn-0.34.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "539fe107-08d7-48b8-83af-ae34384791df",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 625
        },
        "id": "539fe107-08d7-48b8-83af-ae34384791df",
        "outputId": "77020dda-b869-40cc-fea9-7be7a48ca9ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://cf3fd5df86bf611025.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://cf3fd5df86bf611025.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "import gradio as gr\n",
        "import google.generativeai as genai\n",
        "\n",
        "model = genai.GenerativeModel('gemini-2.0-flash')\n",
        "genai.configure(api_key=API_KEY)\n",
        "prompt = '''\n",
        "請依照下面的書籍描述來將書籍進行分類，分類的類別只能從下面複選：\n",
        "[程式語言, Data Science, 人工智慧, 分散式架構, 系統開發, 行動軟體開發, 資料庫, 資訊科學, 軟體架構, 軟體測試, 軟體工程, 資訊安全, 網站開發, 前端開發, 架站軟體, 網頁設計, Adobe 軟體應用, Office 系列, 遊戲開發設計, UI/UX, 雲端運算, 區塊鏈與金融科技, 物聯網 IoT, 商業管理類, 電子電路電機類, 嵌入式系統, 視覺影音設計, 考試認證, 數學, 微軟技術, MAC OS 蘋果電腦, 其他, 兒童專區, 製圖軟體應用, 語言學習, 國家考試, 職涯發展, Java, 理工類, 網路通訊, 量子電腦]\n",
        "\n",
        "<書籍描述>\n",
        "{書籍描述}\n",
        "</書籍描述>\n",
        "\n",
        "輸出請嚴格按照下面的JSON格式\n",
        "<JSON>\n",
        "[類別1, 類別2, 類別3, ]\n",
        "</JSON>\n",
        "'''\n",
        "\n",
        "\n",
        "def book_label(book):\n",
        "    prompt2 = prompt.format(書籍描述=book)\n",
        "    response = model.generate_content(prompt2)\n",
        "    return response.text\n",
        "\n",
        "book_gr = gr.Interface(fn=book_label, inputs=gr.Textbox(label=\"書籍描述\", lines=10),\n",
        "    outputs=gr.Textbox(label=\"分類結果\"))\n",
        "book_gr.launch()\n",
        "# book_label('dummy for java')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "75ce2d13-6e2b-44d9-988a-1ae07edd1ec9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "id": "75ce2d13-6e2b-44d9-988a-1ae07edd1ec9",
        "outputId": "80eff21e-fad0-4c1c-9965-e4668c22f365"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "```json\n",
            "{\n",
            "  \"是否合適\": \"YES\",\n",
            "  \"適任度\": 85,\n",
            "  \"分析\": \"Weber的履歷顯示他具備擔任人工智慧講師的潛力。理由如下：\\n\\n*   **學歷與技能匹配：** 雖然學歷為生物科技，但他透過自學和AI培訓課程，已具備紮實的機器學習和深度學習知識，熟悉Python和PyTorch/TensorFlow等工具，滿足工作需求中對於Python、scikit-learn、Machine Learning、深度學習、人工智慧等工具的擅長要求。\\n*   **跨領域經驗優勢：** 他的跨領域背景（生物科技+人工智慧）使其能夠將AI技術應用於生醫領域，這在課程設計和教學上能提供獨特的視角和案例，尤其現在生醫AI應用相當熱門。\\n*   **專案經驗證明能力：** 緯育AI培訓課程的期末專題經驗，證明他具備模型開發、數據分析、團隊領導和專案管理能力。他擔任專案組長，帶領團隊開發藥物親和性預測模型，並將預測準確率提升至90%以上，顯示其解決問題和達成目標的能力。儘管實際業界經驗未知，但此專案的成功足以彌補。\\n*   **符合工作內容需求：** 履歷中提到的跨領域應用、模型開發與優化、數據分析與處理等技能，與工作內容中的課程設計、備課、新技術導入等需求高度相關。他對CNN、RNN、Transformer等神經網路架構的熟悉，也使他能勝任人工智慧相關課程的教學。\\n* **雖然沒有2年以上工作經驗的要求，但可以透過面試來了解求職者對於授課、表達及問題解決的能力。**\\n* **缺乏業界實務經驗**:雖然有專案經驗，但缺乏在業界實際應用人工智慧的經驗，可能需要時間適應。\\n\\n綜合以上分析，Weber的學歷背景、自學能力、專案經驗和技能都符合工作需求。建議在面試中深入了解其教學能力、表達能力和對人工智慧領域的熱忱，以確認其是否具備擔任人工智慧講師的完整能力。\"\n",
            "}\n",
            "```\n"
          ]
        }
      ],
      "source": [
        "工作需求='''\n",
        "工作內容\n",
        "1. 規劃及執行人工智慧系列課程設計。\n",
        "2. 課程教授與學員學習期間關懷。\n",
        "3. 備課與人工智慧相關新技術之導入。\n",
        "4. 課程教學\n",
        "\n",
        "職務類別\n",
        "講師、資料科學家、演算法工程師\n",
        "工作待遇\n",
        "待遇面議（經常性薪資達 4 萬元或以上）取得專屬你的薪水報告\n",
        "工作性質\n",
        "全職\n",
        "上班地點\n",
        "台北市大安區復興南路1段390號2樓 (距捷運大安站約130公尺)\n",
        "管理責任\n",
        "不需負擔管理責任\n",
        "出差外派\n",
        "無需出差外派\n",
        "上班時段\n",
        "日班\n",
        "休假制度\n",
        "依公司規定\n",
        "可上班日\n",
        "不限\n",
        "需求人數\n",
        "1人\n",
        "條件要求\n",
        "工作經歷\n",
        "2年以上\n",
        "學歷要求\n",
        "專科以上\n",
        "科系要求\n",
        "不拘\n",
        "語文條件\n",
        "不拘\n",
        "\n",
        "擅長工具\n",
        "Python、scikit-learn、OpenCV、Computer Vision、LLM、Prompt\n",
        "提升專業能力\n",
        "工作技能\n",
        "軟體程式設計、Machine Learning、深度學習、人工智慧、語言模型、演算法設計、提示工程、生成式AI\n",
        "其他條件\n",
        "未填寫\n",
        "'''\n",
        "\n",
        "個人履歷='''\n",
        "學歷:國立清華大學 生物科技研究所 碩士\n",
        "自我介紹\n",
        "我是weber，擁有生物科技碩士學位，除了生物科學的研究外，我積極投入人工智慧與深度學習技術的學習與應用，特別是對將機器學習和深度學習技術應用於跨領域上展現出濃厚的興趣，例如生醫領域。我利用空閑時間自學了兩年的相關知識及編程，並透過參與完整的AI培訓課程，我系統性地學習了機器學習和深度學習的相關演算法技術，並熟悉了 Python 程式語言以及 PyTorch 和 TensorFlow 等深度學習框架。儘管我的學術背景並非資訊工程，但我透過自學和專案實踐，努力彌補相關知識的不足，並取得了AI人工智慧相關訓練課程的修習證明，持續提升技術專業度。\n",
        "個人優勢\n",
        "過去的研發工作及研究經驗不僅僅使我熟悉各種研究方法和技術，也使我累積了深厚的科研背景，具備嚴謹的實驗設計與數據分析能力，更訓練我有良好的認真負責的工作態度、邏輯分析與思辯的能力，除此之外，我具備紮實的生物科技與人工智慧技術背景，故能將深度學習技術應用於生物醫學領域。技術專長包括：\n",
        "•\t跨領域應用：熟悉藥物化學與生物學，能將 AI 技術應用於藥物設計、分子模擬與生物標誌物分析，曾針對藥物開發市場設計虛擬預篩選模型。\n",
        "•\t深度學習與機器學習技術：熟悉 CNN、RNN、Transformer 等神經網路架構，能夠針對不同任務設計並調校模型，如影像辨識等。\n",
        "•\t模型開發與優化：熟悉 PyTorch、TensorFlow，能有效應用於構建與優化模型，也能應用 RAG、Fine-tuning 等技術提升大型語言模型性能。\n",
        "•\t數據分析與處理：具備強大的數據前處理、特徵工程與統計分析能力，熟練使用 Pandas、NumPy、Matplotlib、Seaborn 等工具，能有效處理高維度生物數據與藥物特徵。\n",
        "•\t蛋白質藥物製造與分析開發：熟悉蛋白質藥物的製造與分析流程，能使用HPLC及MASS進行胺基酸序列分析，並能針對蛋白質特性進行研究與優化。\n",
        "團隊領導與專案經驗\n",
        "緯育AI培訓課程的期末專題是一次極具挑戰且收穫豐富的經驗。我擔任專案組長，負責帶領跨領域的團隊開發「小分子藥物與蛋白質親和性預測模型」。作為團隊領導者，我不僅要專注於技術細節，還要為團隊提供明確目標，更需要主動協助他人，並確保整體進度順利。因此，我主動定期與組員溝通進度、設定密集的小會議持續追蹤及引導隊員完成任務、分享資源、面對來自不同背景的團隊成員針對不同專業提供回饋等。透過積極的溝通與協調，我們成功克服了種種困難，不僅順利完成了專題，更在最終發表時獲得肯定。擔任組長的經驗更讓我學習到如何設定明確目標、跨領域合作、建立信任、有效追蹤進度並激勵團隊成員，這些經驗都讓我深刻體會到團隊合作的重要性以及領導力的真諦，在成果上專案中整合了藥物化學、生物學與機器學習技術，並透過嚴謹的數據處理，將預測準確率提升至90%以上、F1 score也提升至80%以上。\n",
        "\n",
        "'''\n",
        "\n",
        "工作需求2='''\n",
        "工作內容\n",
        "1.工程請款\n",
        "2.維修保養合約審閱\n",
        "3.開立發票\n",
        "4.處理廠商貨款或費用等應付款項帳務。\n",
        "5.銀行臨櫃匯款等作業。\n",
        "6.需具有1年以上會計經驗。\n",
        "7.主管交辦事項\n",
        "\n",
        "職務類別\n",
        "財務會計助理、記帳／出納／一般會計、財務分析／財務人員\n",
        "工作待遇\n",
        "月薪30,000~35,000元（固定或變動薪資因個人資歷或績效而異）取得專屬你的薪水報告\n",
        "工作性質\n",
        "全職\n",
        "上班地點\n",
        "台北市南港區南港路二段99-3號 (距捷運昆陽站約500公尺)\n",
        "管理責任\n",
        "不需負擔管理責任\n",
        "出差外派\n",
        "無需出差外派\n",
        "上班時段\n",
        "日班，08:30~18:00\n",
        "休假制度\n",
        "週休二日\n",
        "可上班日\n",
        "一個月內\n",
        "需求人數\n",
        "1人\n",
        "條件要求\n",
        "工作經歷\n",
        "1年以上\n",
        "學歷要求\n",
        "高中、專科、大學\n",
        "科系要求\n",
        "財稅金融相關、一般商業學類、會計學相關\n",
        "語文條件\n",
        "英文 -- 聽 /略懂、說 /略懂、讀 /略懂、寫 /略懂\n",
        "\n",
        "提升英文能力\n",
        "擅長工具\n",
        "Windows XP、Excel、PowerPoint、Word、天心資訊\n",
        "提升專業能力\n",
        "工作技能\n",
        "不拘\n",
        "其他條件\n",
        "1.熟悉會計軟體奇德系統尤佳\n",
        "2.工作細心，重視作業細節、具良好溝通、協調能力\n",
        "3.抗壓力高，面對問題或任務時，能獨立思考\n",
        "4.具流程優化能力及經驗佳\n",
        "'''\n",
        "\n",
        "\n",
        "prompt = '''\n",
        "你是一個人資面試官，請依據下面的個人履歷跟工作需求來分析求職者是否適合這份工作：\n",
        "\n",
        "<個人履歷>\n",
        "{個人履歷}\n",
        "</個人履歷>\n",
        "\n",
        "<工作需求>\n",
        "{工作需求}\n",
        "</工作需求>\n",
        "\n",
        "請嚴格按照下面的JSON格式來進行輸出：\n",
        "<JSON>\n",
        "{{'是否合適':'YES'或是'NO','適任度':0~100的評分,'分析':'詳細的理由'}}\n",
        "</JSON>\n",
        "'''\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "response = model.generate_content(prompt.format(個人履歷=個人履歷, 工作需求=工作需求))\n",
        "print(response.text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e1b0faab-d22f-4ac8-9623-65e74054d240",
      "metadata": {
        "id": "e1b0faab-d22f-4ac8-9623-65e74054d240"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}